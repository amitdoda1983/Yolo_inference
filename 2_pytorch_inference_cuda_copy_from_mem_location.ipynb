{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSJOIkxL5lmwmywO/P3A0S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitdoda1983/iith_GPU_inference/blob/main/2_pytorch_inference_cuda_copy_from_mem_location.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Simulate by allocating GPU memory for image being written by smartnic.\n",
        "2. Create a random torch tensor image data in GPU.\n",
        "3. Associate this tensor data to the above GPU memory.\n",
        "4. uptill now, we have image tensor in gpu and memory pointer say gpu_memory\n",
        "5. Now create an zeros torch tensor.\n",
        "6. copy from  gpu_memory to this tensor address.\n",
        "7. work on this tensor for rest of the processing and inference.\n",
        "\n",
        "Note: since pytorch cant access the memory pointer directly, we use pycuda to copy the image tensor from memory pointer (passed by smartnic) to a new torch tensor (in GPU only) which holds zeros.we use this tensor for rest of the flow.\n"
      ],
      "metadata": {
        "id": "HlsdeFG_UCW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3Zg-RS6tDlo",
        "outputId": "5e9c8d14-02dc-4453-c10b-10b681c730db"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.10/dist-packages (2024.1.2)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.10/dist-packages (from pycuda) (2024.1.19)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (4.3.6)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import ctypes\n",
        "import torch\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "\n",
        "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\",\n",
        "    \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\",\n",
        "    \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\",\n",
        "    \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\",\n",
        "    \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
        "    \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\",\n",
        "    \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"TV\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
        "    \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\",\n",
        "    \"hair drier\", \"toothbrush\"]"
      ],
      "metadata": {
        "id": "VkavmsEja0zr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_yolov5_model():\n",
        "    # Load YOLOv5 model (can be replaced with other variants like yolov5m, yolov5l)\n",
        "    model = torch.hub.load('ultralytics/yolov5:v6.2', 'yolov5s')\n",
        "    model = model.cuda()  # Move model to GPU\n",
        "    return model\n",
        "\n",
        "# Run inference using PyTorch (YOLOv5)\n",
        "def infer_on_gpu(model, image_tensor):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(image_tensor)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def postprocess(predictions, conf_threshold=0.5):\n",
        "    pred = predictions[0]\n",
        "    boxes = pred[:, :4]  # Bounding box coordinates\n",
        "    confidences = pred[:, 4]  # Confidence scores\n",
        "    class_probs = pred[:, 5:]  # Class probabilities\n",
        "\n",
        "    # Get predicted class ID\n",
        "    class_ids = torch.argmax(class_probs, dim=1)\n",
        "    overall_confidences = confidences * class_probs.max(dim=1).values\n",
        "\n",
        "    keep = overall_confidences > conf_threshold\n",
        "    boxes = boxes[keep]\n",
        "    confidences = overall_confidences[keep]\n",
        "    class_ids = class_ids[keep]\n",
        "\n",
        "    # Print boxes, confidences, and class ids\n",
        "    for i in range(len(boxes)):\n",
        "        print(f\"Box {i}: {boxes[i]}, Confidence: {confidences[i].item():.2f}, Class ID: {class_ids[i].item()}\")\n",
        "\n",
        "    return boxes, confidences, class_ids"
      ],
      "metadata": {
        "id": "z4eMmOcm0zmO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simulating image from smartnic\n",
        "\n",
        "Assuming the smartnic will pass the pointer to memory"
      ],
      "metadata": {
        "id": "09m-OTbz8pe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Simulate GPU memory passed from SmartNIC (replace actual GPU memory pointer)\n",
        "\n",
        "height, width, channels = 720, 1280, 3  # HWC format\n",
        "image_size = height * width * channels * 4  # Assuming float32 (4 bytes per element)\n",
        "gpu_memory = cuda.mem_alloc(image_size)\n",
        "\n",
        "# Simulate data from the SmartNIC (e.g., randomly generated data)\n",
        "dummy_data = torch.rand(height, width, channels, dtype=torch.float32, device=\"cuda\")\n",
        "\n",
        "\n",
        "# Step 2: Copy data directly from the PyTorch tensor to the GPU memory\n",
        "# Use device-to-device memory copy (dtod)\n",
        "cuda.memcpy_dtod(gpu_memory, dummy_data.data_ptr(), image_size)\n",
        "\n",
        "# Step 3: Access the GPU memory using PyCUDA\n",
        "#use the memory pointer to directly access the data in GPU memory\n",
        "gpu_pointer = int(gpu_memory)  # This is the pointer to GPU memory passed from SmartNIC"
      ],
      "metadata": {
        "id": "le8jEq7k8c1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### copy smartnic image to torch tensor"
      ],
      "metadata": {
        "id": "OK2uQQgX8uCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create a PyTorch zeros tensor directly on the GPU\n",
        "# Allocate a tensor on the GPU with the same shape as the image\n",
        "image_tensor = torch.zeros(height, width, channels, dtype=torch.float32, device=\"cuda\")\n",
        "\n",
        "# Step 5: Copy data from the GPU memory (from SmartNIC) into the PyTorch tensor\n",
        "cuda.memcpy_dtod(image_tensor.data_ptr(), gpu_pointer, image_size)  # Copy data from SmartNIC GPU memory to the tensor"
      ],
      "metadata": {
        "id": "He7VfQwx85tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pre-process and inference"
      ],
      "metadata": {
        "id": "TFXLbQY387aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Preprocess the image for YOLOv5\n",
        "# Convert the image tensor to CHW format (from HWC format)\n",
        "image_tensor = image_tensor.permute(2, 0, 1)  # HWC -> CHW\n",
        "\n",
        "# Resize the image (YOLOv5 expects a 640x640 image for inference)\n",
        "image_tensor = torch.nn.functional.interpolate(image_tensor.unsqueeze(0), size=(640, 640), mode='bilinear', align_corners=False)\n",
        "\n",
        "# Normalize the image (YOLOv5 uses the following normalization)\n",
        "mean = torch.tensor([0.485, 0.456, 0.406], device=image_tensor.device).view(1, 3, 1, 1)\n",
        "std = torch.tensor([0.229, 0.224, 0.225], device=image_tensor.device).view(1, 3, 1, 1)\n",
        "image_tensor = (image_tensor / 255.0 - mean) / std  # Normalize the image to YOLOv5 standards\n",
        "\n",
        "# Step 7: Load YOLOv5 model and perform inference\n",
        "model = load_yolov5_model()\n",
        "predictions = infer_on_gpu(model, image_tensor)\n",
        "\n",
        "# Step 8: Postprocess results\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzLVU4y0a1MT",
        "outputId": "3d87559c-0dbb-4d4b-e6e3-ee8ff7caeacf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_v6.2\n",
            "YOLOv5 🚀 2024-12-8 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 720, 1280])\n",
            "torch.Size([1, 3, 640, 640])\n",
            "torch.Size([1, 3, 640, 640])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[3.51057e+00, 4.11853e+00, 9.09811e+00,  ..., 6.63133e-04, 5.46850e-04, 7.67264e-04],\n",
            "         [9.88525e+00, 3.39440e+00, 1.96917e+01,  ..., 4.27912e-04, 5.07814e-04, 9.80709e-04],\n",
            "         [1.97024e+01, 2.78587e+00, 2.14639e+01,  ..., 4.71157e-04, 6.51654e-04, 2.23510e-03],\n",
            "         ...,\n",
            "         [5.63638e+02, 6.12640e+02, 1.82928e+02,  ..., 1.46065e-03, 1.72118e-03, 1.45068e-03],\n",
            "         [5.87000e+02, 6.07563e+02, 1.37786e+02,  ..., 1.54971e-03, 2.18710e-03, 1.78705e-03],\n",
            "         [6.14991e+02, 6.20093e+02, 1.51012e+02,  ..., 1.91309e-03, 2.60656e-03, 2.49427e-03]]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/torch/hub/ultralytics_yolov5_v6.2/models/common.py:602: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### post process"
      ],
      "metadata": {
        "id": "Z0mFSvB29FZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Post-process the results\n",
        "boxes, confidences, class_ids = postprocess(predictions, conf_threshold=0.01)\n",
        "\n",
        "for i, class_id in enumerate(class_ids):\n",
        "    print(f\"Class {class_names[class_id.item()]} with confidence {confidences[i].item():.2f}: {boxes[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6rFkVql18FQ",
        "outputId": "6233af8e-8c75-4c52-9725-72b47b815b14"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Box 0: tensor([287.92484, 285.01569, 651.25946, 581.83923], device='cuda:0'), Confidence: 0.01, Class ID: 6\n",
            "Box 1: tensor([287.02585, 307.47607, 653.79816, 629.22656], device='cuda:0'), Confidence: 0.02, Class ID: 6\n",
            "Box 2: tensor([286.52527, 335.21878, 653.52380, 623.64349], device='cuda:0'), Confidence: 0.02, Class ID: 6\n",
            "Class train with confidence 0.01: tensor([287.92484, 285.01569, 651.25946, 581.83923], device='cuda:0')\n",
            "Class train with confidence 0.02: tensor([287.02585, 307.47607, 653.79816, 629.22656], device='cuda:0')\n",
            "Class train with confidence 0.02: tensor([286.52527, 335.21878, 653.52380, 623.64349], device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}